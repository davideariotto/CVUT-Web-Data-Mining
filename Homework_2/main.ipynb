{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining from \"The Great Gatsby\"\n",
    "\n",
    "## Introduction\n",
    "I decided to perform the text mining task on the novel \"The Great Gatsby\" by F. Scott Fitzgerald. I found a complete .txt file of the book on the site \"Project Gutenberg\".\n",
    "\n",
    "## Top entities\n",
    "For each step entities have been counted and sorted by descending order to select the most common ones. After each code cell there can be seen the results but to sum up these are the most common ones divided by category:\n",
    "- people: Gatsby, Tom, Daisy, Jordan, Wilson ...\n",
    "- places: New York, West Egg, East Egg, Oxford, ...\n",
    "- organizations/other: the rest\n",
    "\n",
    "## Results comparation\n",
    "I selected a couple sentences for doing a precise comparation but more extensive results are available by running the notebook.\n",
    "The nlt based classification just recognized this 5 entities from the whole senteces so I'll compare them:\n",
    "- East Egg (it's a place)\n",
    "- Tom Buchanans (it's a character of the novel)\n",
    "- Daisy (another character)\n",
    "- Tom (same character as before but just the name)\n",
    "- Chicago (a place)\n",
    "\n",
    "### nltk-based classification\n",
    "- East Egg (LOCATION)\n",
    "- Tom Buchanans (ORGANIZATION)\n",
    "- Daisy (PERSON)\n",
    "- Tom (PERSON)\n",
    "- Chicago (GPE)\n",
    "\n",
    "### wikipedia-based classification\n",
    "- East Egg = a Thing (I thought it recognized it because it's a very specific name, existing only in the book)\n",
    "- Tom Buchanans = a Thing (also very specific, I expected it would have recognized it)\n",
    "- Daisy = A day (wrong)\n",
    "- Tom = a Thing (I expected this was easy, it's a very common first name)\n",
    "- Chicago = shih-KAH-goh (correct classification but the summary is wrong, it reported the pronounciation)\n",
    "\n",
    "### language model classification\n",
    "- East Egg = location / miscellaneous (east as location but it doesn't recognize the whole 'east egg' concept)\n",
    "- Tom Buchanans = person (correct)\n",
    "- Daisy = person (correct)\n",
    "- Tom = person (correct)\n",
    "- Chicago = location (correct)\n",
    "\n",
    "\n",
    "### To sum up:\n",
    "- nltk-based classification: it worked great, classifying as people all the characters and as locations almost all of the places.\n",
    "- wikipedia-based classification using nltk entities as the input: the results are definitely not satisying but I came to the idea that when you look on wikipedia for something that return multiple results (like \"Gatsby\" returns 3 pages) the library function return null, so it is classified as 'a Thing'.\n",
    "- wikipedia-based classification using custom patterns as the input: basically the same as the other wikipedia-based classification approach\n",
    "- language model classifications: I chose BERT and it performed really well, but we have to remember that it's more computationally expensive.\n",
    "\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "import wikipedia\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 ) Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open('the_great_gatsby.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines:\n",
    "    # Delete all of the \"Chapter ...\"\n",
    "    if 'Chapter' in line:\n",
    "        continue\n",
    "    else:\n",
    "        text = text + line.replace('\"', \"\").replace('``','').replace('--','')\n",
    "\n",
    "# I selected a cople sentences for the comparison task (line 141-146 of the txt file)        \n",
    "text_for_comparation = \"Across the courtesy bay the white palaces of fashionable East Egg glittered along the water, and the history of the summer really begins on the evening I drove over there to have dinner with Tom Buchanans. Daisy was my second cousin once removed and I'd known Tom in college. And just after the war I spent two days with them in Chicago\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ) POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('In', 'IN'), ('my', 'PRP$'), ('younger', 'JJR'), ('and', 'CC'), ('more', 'RBR'), ('vulnerable', 'JJ'), ('years', 'NNS'), ('my', 'PRP$'), ('father', 'NN'), ('gave', 'VBD'), ('me', 'PRP'), ('some', 'DT'), ('advice', 'NN'), ('that', 'IN'), ('I', 'PRP'), (\"'ve\", 'VBP'), ('been', 'VBN'), ('turning', 'VBG'), ('over', 'IN'), ('in', 'IN'), ('my', 'PRP$'), ('mind', 'NN'), ('ever', 'RB'), ('since', 'IN'), ('.', '.')], [('Whenever', 'WRB'), ('you', 'PRP'), ('feel', 'VBP'), ('like', 'IN'), ('criticizing', 'VBG'), ('any', 'DT'), ('one', 'CD'), (',', ','), ('he', 'PRP'), ('told', 'VBD'), ('me', 'PRP'), (',', ','), ('just', 'RB'), ('remember', 'VB'), ('that', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('have', 'VBP'), (\"n't\", 'RB'), ('had', 'VBD'), ('the', 'DT'), ('advantages', 'NNS'), ('that', 'IN'), ('you', 'PRP'), (\"'ve\", 'VBP'), ('had', 'VBN'), ('.', '.')], [('He', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('say', 'VB'), ('any', 'DT'), ('more', 'JJR'), ('but', 'CC'), ('we', 'PRP'), (\"'ve\", 'VBP'), ('always', 'RB'), ('been', 'VBN'), ('unusually', 'RB'), ('communicative', 'JJ'), ('in', 'IN'), ('a', 'DT'), ('reserved', 'JJ'), ('way', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('understood', 'VBP'), ('that', 'IN'), ('he', 'PRP'), ('meant', 'VBD'), ('a', 'DT'), ('great', 'JJ'), ('deal', 'NN'), ('more', 'JJR'), ('than', 'IN'), ('that', 'DT'), ('.', '.')], [('In', 'IN'), ('consequence', 'NN'), ('I', 'PRP'), (\"'m\", 'VBP'), ('inclined', 'JJ'), ('to', 'TO'), ('reserve', 'VB'), ('all', 'DT'), ('judgments', 'NNS'), (',', ','), ('a', 'DT'), ('habit', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('opened', 'VBN'), ('up', 'RP'), ('many', 'JJ'), ('curious', 'JJ'), ('natures', 'NNS'), ('to', 'TO'), ('me', 'PRP'), ('and', 'CC'), ('also', 'RB'), ('made', 'VBD'), ('me', 'PRP'), ('the', 'DT'), ('victim', 'NN'), ('of', 'IN'), ('not', 'RB'), ('a', 'DT'), ('few', 'JJ'), ('veteran', 'NN'), ('bores', 'NNS'), ('.', '.')], [('The', 'DT'), ('abnormal', 'JJ'), ('mind', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('to', 'TO'), ('detect', 'VB'), ('and', 'CC'), ('attach', 'VB'), ('itself', 'PRP'), ('to', 'TO'), ('this', 'DT'), ('quality', 'NN'), ('when', 'WRB'), ('it', 'PRP'), ('appears', 'VBZ'), ('in', 'IN'), ('a', 'DT'), ('normal', 'JJ'), ('person', 'NN'), (',', ','), ('and', 'CC'), ('so', 'RB'), ('it', 'PRP'), ('came', 'VBD'), ('about', 'IN'), ('that', 'DT'), ('in', 'IN'), ('college', 'NN'), ('I', 'PRP'), ('was', 'VBD'), ('unjustly', 'RB'), ('accused', 'VBN'), ('of', 'IN'), ('being', 'VBG'), ('a', 'DT'), ('politician', 'NN'), (',', ','), ('because', 'IN'), ('I', 'PRP'), ('was', 'VBD'), ('privy', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('secret', 'JJ'), ('griefs', 'NN'), ('of', 'IN'), ('wild', 'JJ'), (',', ','), ('unknown', 'JJ'), ('men', 'NNS'), ('.', '.')], [('Most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('confidences', 'NNS'), ('were', 'VBD'), ('unsoughtfrequently', 'RB'), ('I', 'PRP'), ('have', 'VBP'), ('feigned', 'VBN'), ('sleep', 'NN'), (',', ','), ('preoccupation', 'NN'), (',', ','), ('or', 'CC'), ('a', 'DT'), ('hostile', 'JJ'), ('levity', 'NN'), ('when', 'WRB'), ('I', 'PRP'), ('realized', 'VBN'), ('by', 'IN'), ('some', 'DT'), ('unmistakable', 'JJ'), ('sign', 'NN'), ('that', 'IN'), ('an', 'DT'), ('intimate', 'JJ'), ('revelation', 'NN'), ('was', 'VBD'), ('quivering', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('horizonfor', 'NN'), ('the', 'DT'), ('intimate', 'JJ'), ('revelations', 'NNS'), ('of', 'IN'), ('young', 'JJ'), ('men', 'NNS'), ('or', 'CC'), ('at', 'IN'), ('least', 'JJS'), ('the', 'DT'), ('terms', 'NNS'), ('in', 'IN'), ('which', 'WDT'), ('they', 'PRP'), ('express', 'VBP'), ('them', 'PRP'), ('are', 'VBP'), ('usually', 'RB'), ('plagiaristic', 'JJ'), ('and', 'CC'), ('marred', 'VBN'), ('by', 'IN'), ('obvious', 'JJ'), ('suppressions', 'NNS'), ('.', '.')], [('Reserving', 'VBG'), ('judgments', 'NNS'), ('is', 'VBZ'), ('a', 'DT'), ('matter', 'NN'), ('of', 'IN'), ('infinite', 'JJ'), ('hope', 'NN'), ('.', '.')], [('I', 'PRP'), ('am', 'VBP'), ('still', 'RB'), ('a', 'DT'), ('little', 'JJ'), ('afraid', 'NN'), ('of', 'IN'), ('missing', 'VBG'), ('something', 'NN'), ('if', 'IN'), ('I', 'PRP'), ('forget', 'VBP'), ('that', 'RB'), (',', ','), ('as', 'IN'), ('my', 'PRP$'), ('father', 'NN'), ('snobbishly', 'RB'), ('suggested', 'VBN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('snobbishly', 'RB'), ('repeat', 'NN'), (',', ','), ('a', 'DT'), ('sense', 'NN'), ('of', 'IN'), ('the', 'DT'), ('fundamental', 'JJ'), ('decencies', 'NNS'), ('is', 'VBZ'), ('parcelled', 'VBN'), ('out', 'RP'), ('unequally', 'RB'), ('at', 'IN'), ('birth', 'NN'), ('.', '.')], [('And', 'CC'), (',', ','), ('after', 'IN'), ('boasting', 'VBG'), ('this', 'DT'), ('way', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('tolerance', 'NN'), (',', ','), ('I', 'PRP'), ('come', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('admission', 'NN'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('a', 'DT'), ('limit', 'NN'), ('.', '.')], [('Conduct', 'NN'), ('may', 'MD'), ('be', 'VB'), ('founded', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('hard', 'JJ'), ('rock', 'NN'), ('or', 'CC'), ('the', 'DT'), ('wet', 'JJ'), ('marshes', 'NNS'), ('but', 'CC'), ('after', 'IN'), ('a', 'DT'), ('certain', 'JJ'), ('point', 'NN'), ('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('care', 'VB'), ('what', 'WP'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('founded', 'VBN'), ('on', 'IN'), ('.', '.')], [('When', 'WRB'), ('I', 'PRP'), ('came', 'VBD'), ('back', 'RB'), ('from', 'IN'), ('the', 'DT'), ('East', 'NNP'), ('last', 'JJ'), ('autumn', 'NN'), ('I', 'PRP'), ('felt', 'VBD'), ('that', 'IN'), ('I', 'PRP'), ('wanted', 'VBD'), ('the', 'DT'), ('world', 'NN'), ('to', 'TO'), ('be', 'VB'), ('in', 'IN'), ('uniform', 'JJ'), ('and', 'CC'), ('at', 'IN'), ('a', 'DT'), ('sort', 'NN'), ('of', 'IN'), ('moral', 'JJ'), ('attention', 'NN'), ('forever', 'RB'), (';', ':'), ('I', 'PRP'), ('wanted', 'VBD'), ('no', 'DT'), ('more', 'RBR'), ('riotous', 'JJ'), ('excursions', 'NNS'), ('with', 'IN'), ('privileged', 'JJ'), ('glimpses', 'NNS'), ('into', 'IN'), ('the', 'DT'), ('human', 'JJ'), ('heart', 'NN'), ('.', '.')], [('Only', 'RB'), ('Gatsby', 'NNP'), (',', ','), ('the', 'DT'), ('man', 'NN'), ('who', 'WP'), ('gives', 'VBZ'), ('his', 'PRP$'), ('name', 'NN'), ('to', 'TO'), ('this', 'DT'), ('book', 'NN'), (',', ','), ('was', 'VBD'), ('exempt', 'JJ'), ('from', 'IN'), ('my', 'PRP$'), ('reactionGatsby', 'NN'), ('who', 'WP'), ('represented', 'VBD'), ('everything', 'NN'), ('for', 'IN'), ('which', 'WDT'), ('I', 'PRP'), ('have', 'VBP'), ('an', 'DT'), ('unaffected', 'JJ'), ('scorn', 'NN'), ('.', '.')], [('If', 'IN'), ('personality', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('unbroken', 'JJ'), ('series', 'NN'), ('of', 'IN'), ('successful', 'JJ'), ('gestures', 'NNS'), (',', ','), ('then', 'RB'), ('there', 'EX'), ('was', 'VBD'), ('something', 'NN'), ('gorgeous', 'JJ'), ('about', 'IN'), ('him', 'PRP'), (',', ','), ('some', 'DT'), ('heightened', 'VBN'), ('sensitivity', 'NN'), ('to', 'TO'), ('the', 'DT'), ('promises', 'NNS'), ('of', 'IN'), ('life', 'NN'), (',', ','), ('as', 'IN'), ('if', 'IN'), ('he', 'PRP'), ('were', 'VBD'), ('related', 'VBN'), ('to', 'TO'), ('one', 'CD'), ('of', 'IN'), ('those', 'DT'), ('intricate', 'JJ'), ('machines', 'NNS'), ('that', 'IN'), ('register', 'NN'), ('earthquakes', 'NNS'), ('ten', 'VBP'), ('thousand', 'VBP'), ('miles', 'NNS'), ('away', 'RB'), ('.', '.')], [('This', 'DT'), ('responsiveness', 'NN'), ('had', 'VBD'), ('nothing', 'NN'), ('to', 'TO'), ('do', 'VB'), ('with', 'IN'), ('that', 'DT'), ('flabby', 'NN'), ('impressionability', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('dignified', 'VBN'), ('under', 'IN'), ('the', 'DT'), ('name', 'NN'), ('of', 'IN'), ('the', 'DT'), ('creative', 'JJ'), ('temperamentit', 'NN'), ('was', 'VBD'), ('an', 'DT'), ('extraordinary', 'JJ'), ('gift', 'NN'), ('for', 'IN'), ('hope', 'NN'), (',', ','), ('a', 'DT'), ('romantic', 'JJ'), ('readiness', 'NN'), ('such', 'JJ'), ('as', 'IN'), ('I', 'PRP'), ('have', 'VBP'), ('never', 'RB'), ('found', 'VBN'), ('in', 'IN'), ('any', 'DT'), ('other', 'JJ'), ('person', 'NN'), ('and', 'CC'), ('which', 'WDT'), ('it', 'PRP'), ('is', 'VBZ'), ('not', 'RB'), ('likely', 'JJ'), ('I', 'PRP'), ('shall', 'MD'), ('ever', 'RB'), ('find', 'VB'), ('again', 'RB'), ('.', '.')], [('NoGatsby', 'NNP'), ('turned', 'VBD'), ('out', 'RP'), ('all', 'RB'), ('right', 'RB'), ('at', 'IN'), ('the', 'DT'), ('end', 'NN'), (';', ':'), ('it', 'PRP'), ('is', 'VBZ'), ('what', 'WP'), ('preyed', 'VBD'), ('on', 'IN'), ('Gatsby', 'NNP'), (',', ','), ('what', 'WP'), ('foul', 'VBD'), ('dust', 'NN'), ('floated', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('wake', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('dreams', 'NNS'), ('that', 'IN'), ('temporarily', 'RB'), ('closed', 'VBN'), ('out', 'RP'), ('my', 'PRP$'), ('interest', 'NN'), ('in', 'IN'), ('the', 'DT'), ('abortive', 'JJ'), ('sorrows', 'NNS'), ('and', 'CC'), ('short-winded', 'JJ'), ('elations', 'NNS'), ('of', 'IN'), ('men', 'NNS'), ('.', '.')], [('My', 'PRP$'), ('family', 'NN'), ('have', 'VBP'), ('been', 'VBN'), ('prominent', 'JJ'), (',', ','), ('well-to-do', 'JJ'), ('people', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('middle-western', 'JJ'), ('city', 'NN'), ('for', 'IN'), ('three', 'CD'), ('generations', 'NNS'), ('.', '.')], [('The', 'DT'), ('Carraways', 'NNPS'), ('are', 'VBP'), ('something', 'NN'), ('of', 'IN'), ('a', 'DT'), ('clan', 'NN'), ('and', 'CC'), ('we', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('tradition', 'NN'), ('that', 'IN'), ('we', 'PRP'), (\"'re\", 'VBP'), ('descended', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('Dukes', 'NNP'), ('of', 'IN'), ('Buccleuch', 'NNP'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('actual', 'JJ'), ('founder', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('line', 'NN'), ('was', 'VBD'), ('my', 'PRP$'), ('grandfather', 'NN'), (\"'s\", 'POS'), ('brother', 'NN'), ('who', 'WP'), ('came', 'VBD'), ('here', 'RB'), ('in', 'IN'), ('fifty-one', 'NN'), (',', ','), ('sent', 'VBD'), ('a', 'DT'), ('substitute', 'NN'), ('to', 'TO'), ('the', 'DT'), ('Civil', 'NNP'), ('War', 'NNP'), ('and', 'CC'), ('started', 'VBD'), ('the', 'DT'), ('wholesale', 'JJ'), ('hardware', 'NN'), ('business', 'NN'), ('that', 'IN'), ('my', 'PRP$'), ('father', 'NN'), ('carries', 'VBZ'), ('on', 'IN'), ('today', 'NN'), ('.', '.')], [('I', 'PRP'), ('never', 'RB'), ('saw', 'VBD'), ('this', 'DT'), ('great-uncle', 'NN'), ('but', 'CC'), ('I', 'PRP'), (\"'m\", 'VBP'), ('supposed', 'VBN'), ('to', 'TO'), ('look', 'VB'), ('like', 'IN'), ('himwith', 'NN'), ('special', 'JJ'), ('reference', 'NN'), ('to', 'TO'), ('the', 'DT'), ('rather', 'RB'), ('hard-boiled', 'JJ'), ('painting', 'NN'), ('that', 'WDT'), ('hangs', 'VBZ'), ('in', 'IN'), ('Father', 'NNP'), (\"'s\", 'POS'), ('office', 'NN'), ('.', '.')], [('I', 'PRP'), ('graduated', 'VBD'), ('from', 'IN'), ('New', 'NNP'), ('Haven', 'NNP'), ('in', 'IN'), ('1915', 'CD'), (',', ','), ('just', 'RB'), ('a', 'DT'), ('quarter', 'NN'), ('of', 'IN'), ('a', 'DT'), ('century', 'NN'), ('after', 'IN'), ('my', 'PRP$'), ('father', 'NN'), (',', ','), ('and', 'CC'), ('a', 'DT'), ('little', 'JJ'), ('later', 'JJ'), ('I', 'PRP'), ('participated', 'VBD'), ('in', 'IN'), ('that', 'DT'), ('delayed', 'VBD'), ('Teutonic', 'NNP'), ('migration', 'NN'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('Great', 'NNP'), ('War', 'NNP'), ('.', '.')], [('I', 'PRP'), ('enjoyed', 'VBD'), ('the', 'DT'), ('counter-raid', 'NN'), ('so', 'RB'), ('thoroughly', 'RB'), ('that', 'IN'), ('I', 'PRP'), ('came', 'VBD'), ('back', 'RB'), ('restless', 'NN'), ('.', '.')], [('Instead', 'RB'), ('of', 'IN'), ('being', 'VBG'), ('the', 'DT'), ('warm', 'JJ'), ('center', 'NN'), ('of', 'IN'), ('the', 'DT'), ('world', 'NN'), ('the', 'DT'), ('middle-west', 'JJS'), ('now', 'RB'), ('seemed', 'VBN'), ('like', 'IN'), ('the', 'DT'), ('ragged', 'JJ'), ('edge', 'NN'), ('of', 'IN'), ('the', 'DT'), ('universeso', 'JJ'), ('I', 'PRP'), ('decided', 'VBD'), ('to', 'TO'), ('go', 'VB'), ('east', 'JJ'), ('and', 'CC'), ('learn', 'VB'), ('the', 'DT'), ('bond', 'NN'), ('business', 'NN'), ('.', '.')], [('Everybody', 'NN'), ('I', 'PRP'), ('knew', 'VBD'), ('was', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('bond', 'NN'), ('business', 'NN'), ('so', 'RB'), ('I', 'PRP'), ('supposed', 'VBD'), ('it', 'PRP'), ('could', 'MD'), ('support', 'VB'), ('one', 'CD'), ('more', 'JJR'), ('single', 'JJ'), ('man', 'NN'), ('.', '.')], [('All', 'DT'), ('my', 'PRP$'), ('aunts', 'NNS'), ('and', 'CC'), ('uncles', 'NNS'), ('talked', 'VBD'), ('it', 'PRP'), ('over', 'RP'), ('as', 'IN'), ('if', 'IN'), ('they', 'PRP'), ('were', 'VBD'), ('choosing', 'VBG'), ('a', 'DT'), ('prep-school', 'NN'), ('for', 'IN'), ('me', 'PRP'), ('and', 'CC'), ('finally', 'RB'), ('said', 'VBD'), (',', ','), ('Whyye-es', 'NNP'), ('with', 'IN'), ('very', 'RB'), ('grave', 'JJ'), (',', ','), ('hesitant', 'JJ'), ('faces', 'VBZ'), ('.', '.')], [('Father', 'NNP'), ('agreed', 'VBD'), ('to', 'TO'), ('finance', 'VB'), ('me', 'PRP'), ('for', 'IN'), ('a', 'DT'), ('year', 'NN'), ('and', 'CC'), ('after', 'IN'), ('various', 'JJ'), ('delays', 'NNS'), ('I', 'PRP'), ('came', 'VBD'), ('east', 'RB'), (',', ','), ('permanently', 'RB'), (',', ','), ('I', 'PRP'), ('thought', 'VBD'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('spring', 'NN'), ('of', 'IN'), ('twenty-two', 'NN'), ('.', '.')], [('The', 'DT'), ('practical', 'JJ'), ('thing', 'NN'), ('was', 'VBD'), ('to', 'TO'), ('find', 'VB'), ('rooms', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('city', 'NN'), ('but', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('warm', 'JJ'), ('season', 'NN'), ('and', 'CC'), ('I', 'PRP'), ('had', 'VBD'), ('just', 'RB'), ('left', 'VBN'), ('a', 'DT'), ('country', 'NN'), ('of', 'IN'), ('wide', 'JJ'), ('lawns', 'NNS'), ('and', 'CC'), ('friendly', 'JJ'), ('trees', 'NNS'), (',', ','), ('so', 'RB'), ('when', 'WRB'), ('a', 'DT'), ('young', 'JJ'), ('man', 'NN'), ('at', 'IN'), ('the', 'DT'), ('office', 'NN'), ('suggested', 'VBD'), ('that', 'IN'), ('we', 'PRP'), ('take', 'VBP'), ('a', 'DT'), ('house', 'NN'), ('together', 'RB'), ('in', 'IN'), ('a', 'DT'), ('commuting', 'VBG'), ('town', 'NN'), ('it', 'PRP'), ('sounded', 'VBD'), ('like', 'IN'), ('a', 'DT'), ('great', 'JJ'), ('idea', 'NN'), ('.', '.')], [('He', 'PRP'), ('found', 'VBD'), ('the', 'DT'), ('house', 'NN'), (',', ','), ('a', 'DT'), ('weather', 'NN'), ('beaten', 'RB'), ('cardboard', 'RB'), ('bungalow', 'NN'), ('at', 'IN'), ('eighty', 'FW'), ('a', 'DT'), ('month', 'NN'), (',', ','), ('but', 'CC'), ('at', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('minute', 'NN'), ('the', 'DT'), ('firm', 'NN'), ('ordered', 'VBD'), ('him', 'PRP'), ('to', 'TO'), ('Washington', 'NNP'), ('and', 'CC'), ('I', 'PRP'), ('went', 'VBD'), ('out', 'IN'), ('to', 'TO'), ('the', 'DT'), ('country', 'NN'), ('alone', 'RB'), ('.', '.')], [('I', 'PRP'), ('had', 'VBD'), ('a', 'DT'), ('dog', 'NN'), (',', ','), ('at', 'IN'), ('least', 'JJS'), ('I', 'PRP'), ('had', 'VBD'), ('him', 'PRP'), ('for', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('days', 'NNS'), ('until', 'IN'), ('he', 'PRP'), ('ran', 'VBD'), ('away', 'RB'), (',', ','), ('and', 'CC'), ('an', 'DT'), ('old', 'JJ'), ('Dodge', 'NNP'), ('and', 'CC'), ('a', 'DT'), ('Finnish', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('made', 'VBD'), ('my', 'PRP$'), ('bed', 'NN'), ('and', 'CC'), ('cooked', 'VBD'), ('breakfast', 'NN'), ('and', 'CC'), ('muttered', 'VBD'), ('Finnish', 'JJ'), ('wisdom', 'NN'), ('to', 'TO'), ('herself', 'VB'), ('over', 'IN'), ('the', 'DT'), ('electric', 'JJ'), ('stove', 'NN'), ('.', '.')], [('It', 'PRP'), ('was', 'VBD'), ('lonely', 'RB'), ('for', 'IN'), ('a', 'DT'), ('day', 'NN'), ('or', 'CC'), ('so', 'RB'), ('until', 'IN'), ('one', 'CD'), ('morning', 'NN'), ('some', 'DT'), ('man', 'NN'), (',', ','), ('more', 'RBR'), ('recently', 'RB'), ('arrived', 'VBD'), ('than', 'IN'), ('I', 'PRP'), (',', ','), ('stopped', 'VBD'), ('me', 'PRP'), ('on', 'IN'), ('the', 'DT'), ('road', 'NN'), ('.', '.')], [('How', 'WRB'), ('do', 'VB'), ('you', 'PRP'), ('get', 'VB'), ('to', 'TO'), ('West', 'NNP'), ('Egg', 'NNP'), ('village', 'NN'), ('?', '.')], [('he', 'PRP'), ('asked', 'VBD'), ('helplessly', 'RB'), ('.', '.')], [('I', 'PRP'), ('told', 'VBD'), ('him', 'PRP'), ('.', '.')], [('And', 'CC'), ('as', 'IN'), ('I', 'PRP'), ('walked', 'VBD'), ('on', 'IN'), ('I', 'PRP'), ('was', 'VBD'), ('lonely', 'RB'), ('no', 'RB'), ('longer', 'RBR'), ('.', '.')], [('I', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('guide', 'NN'), (',', ','), ('a', 'DT'), ('pathfinder', 'NN'), (',', ','), ('an', 'DT'), ('original', 'JJ'), ('settler', 'NN'), ('.', '.')], [('He', 'PRP'), ('had', 'VBD'), ('casually', 'RB'), ('conferred', 'VBN'), ('on', 'IN'), ('me', 'PRP'), ('the', 'DT'), ('freedom', 'NN'), ('of', 'IN'), ('the', 'DT'), ('neighborhood', 'NN'), ('.', '.')], [('And', 'CC'), ('so', 'RB'), ('with', 'IN'), ('the', 'DT'), ('sunshine', 'NN'), ('and', 'CC'), ('the', 'DT'), ('great', 'JJ'), ('bursts', 'NNS'), ('of', 'IN'), ('leaves', 'NNS'), ('growing', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('treesjust', 'NN'), ('as', 'IN'), ('things', 'NNS'), ('grow', 'VBP'), ('in', 'IN'), ('fast', 'JJ'), ('moviesI', 'NN'), ('had', 'VBD'), ('that', 'IN'), ('familiar', 'JJ'), ('conviction', 'NN'), ('that', 'IN'), ('life', 'NN'), ('was', 'VBD'), ('beginning', 'VBG'), ('over', 'RP'), ('again', 'RB'), ('with', 'IN'), ('the', 'DT'), ('summer', 'NN'), ('.', '.')], [('There', 'EX'), ('was', 'VBD'), ('so', 'RB'), ('much', 'JJ'), ('to', 'TO'), ('read', 'VB'), ('for', 'IN'), ('one', 'CD'), ('thing', 'NN'), ('and', 'CC'), ('so', 'RB'), ('much', 'JJ'), ('fine', 'JJ'), ('health', 'NN'), ('to', 'TO'), ('be', 'VB'), ('pulled', 'VBN'), ('down', 'RP'), ('out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('young', 'JJ'), ('breath-giving', 'JJ'), ('air', 'NN'), ('.', '.')], [('I', 'PRP'), ('bought', 'VBD'), ('a', 'DT'), ('dozen', 'NN'), ('volumes', 'NNS'), ('on', 'IN'), ('banking', 'NN'), ('and', 'CC'), ('credit', 'NN'), ('and', 'CC'), ('investment', 'NN'), ('securities', 'NNS'), ('and', 'CC'), ('they', 'PRP'), ('stood', 'VBD'), ('on', 'IN'), ('my', 'PRP$'), ('shelf', 'NN'), ('in', 'IN'), ('red', 'JJ'), ('and', 'CC'), ('gold', 'NN'), ('like', 'IN'), ('new', 'JJ'), ('money', 'NN'), ('from', 'IN'), ('the', 'DT'), ('mint', 'NN'), (',', ','), ('promising', 'VBG'), ('to', 'TO'), ('unfold', 'VB'), ('the', 'DT'), ('shining', 'VBG'), ('secrets', 'NNS'), ('that', 'IN'), ('only', 'RB'), ('Midas', 'NNP'), ('and', 'CC'), ('Morgan', 'NNP'), ('and', 'CC'), ('Maecenas', 'NNP'), ('knew', 'VBD'), ('.', '.')], [('And', 'CC'), ('I', 'PRP'), ('had', 'VBD'), ('the', 'DT'), ('high', 'JJ'), ('intention', 'NN'), ('of', 'IN'), ('reading', 'VBG'), ('many', 'JJ'), ('other', 'JJ'), ('books', 'NNS'), ('besides', 'IN'), ('.', '.')], [('I', 'PRP'), ('was', 'VBD'), ('rather', 'RB'), ('literary', 'JJ'), ('in', 'IN'), ('collegeone', 'JJ'), ('year', 'NN'), ('I', 'PRP'), ('wrote', 'VBD'), ('a', 'DT'), ('series', 'NN'), ('of', 'IN'), ('very', 'RB'), ('solemn', 'JJ'), ('and', 'CC'), ('obvious', 'JJ'), ('editorials', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('Yale', 'NNP'), ('Newsand', 'NNP'), ('now', 'RB'), ('I', 'PRP'), ('was', 'VBD'), ('going', 'VBG'), ('to', 'TO'), ('bring', 'VB'), ('back', 'RB'), ('all', 'DT'), ('such', 'JJ'), ('things', 'NNS'), ('into', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('and', 'CC'), ('become', 'VB'), ('again', 'RB'), ('that', 'IN'), ('most', 'JJS'), ('limited', 'JJ'), ('of', 'IN'), ('all', 'DT'), ('specialists', 'NNS'), (',', ','), ('the', 'DT'), ('well-rounded', 'JJ'), ('man', 'NN'), ('.', '.')], [('This', 'DT'), ('is', 'VBZ'), (\"n't\", 'RB'), ('just', 'RB'), ('an', 'DT'), ('epigramlife', 'NN'), ('is', 'VBZ'), ('much', 'RB'), ('more', 'RBR'), ('successfully', 'RB'), ('looked', 'VBN'), ('at', 'IN'), ('from', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('window', 'NN'), (',', ','), ('after', 'IN'), ('all', 'DT'), ('.', '.')]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "POS Top 10\n",
      "[(('.', '.'), 3203), (('the', 'DT'), 2203), ((',', ','), 2197), (('and', 'CC'), 1471), (('I', 'PRP'), 1368), (('a', 'DT'), 1331), (('to', 'TO'), 1119), (('of', 'IN'), 1097), (('was', 'VBD'), 800), (('in', 'IN'), 767)]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "POS Top 10 filtered\n",
      "[(('I', 'PRP'), 1368), (('Gatsby', 'NNP'), 251), (('He', 'PRP'), 245), (('said', 'VBD'), 232), (('Tom', 'NNP'), 188), (('Daisy', 'NNP'), 177), (('The', 'DT'), 171), (('It', 'PRP'), 152), (('one', 'CD'), 149), (('She', 'PRP'), 123)]\n"
     ]
    }
   ],
   "source": [
    "# Performing POS on the original text\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "tokens = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "tagged = [nltk.pos_tag(sent) for sent in tokens]\n",
    "print(tagged[:40])\n",
    "print(\"\\n\"+\"-\"*100+\"\\n\")\n",
    "\n",
    "# Counting the tags and printing the most common ones\n",
    "pos = [item for sublist in tagged for item in sublist]\n",
    "count = Counter(pos)\n",
    "sort_pos = sorted(count.items(), key=lambda count:count[1], reverse=True)\n",
    "print('POS Top 10')\n",
    "print(sort_pos[:10])\n",
    "print(\"\\n\"+\"-\"*100+\"\\n\")\n",
    "\n",
    "# Filtering the original text and doing POS\n",
    "flattened_tokens = [item for sublist in tokens for item in sublist]\n",
    "filtered_tokens = [token for token in flattened_tokens \n",
    "                       if token not in string.punctuation \n",
    "                       if token not in nltk.corpus.stopwords.words('english')\n",
    "                       if \"'\" not in token]\n",
    "tagged = nltk.pos_tag(filtered_tokens)\n",
    "\n",
    "# Counting again\n",
    "count = Counter(tagged)\n",
    "sort_tagged = sorted(count.items(), key=lambda count:count[1], reverse=True)\n",
    "print('POS Top 10 filtered')\n",
    "print(sort_tagged[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ) NER with entity classification (using nltk.ne_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Top 20\n",
      "count --> entity\n",
      "--------------------------------------------------------------------------------\n",
      "212 --> Gatsby (PERSON)\n",
      "163 --> Tom (PERSON)\n",
      "162 --> Daisy (PERSON)\n",
      "67 --> Wilson (PERSON)\n",
      "57 --> Jordan (PERSON)\n",
      "30 --> New York (GPE)\n",
      "25 --> Miss Baker (PERSON)\n",
      "22 --> Mr. Gatsby (PERSON)\n",
      "22 --> Michaelis (PERSON)\n",
      "21 --> Nick (PERSON)\n",
      "20 --> West Egg (LOCATION)\n",
      "19 --> Chicago (GPE)\n",
      "17 --> Tom Buchanan (PERSON)\n",
      "16 --> Myrtle (PERSON)\n",
      "16 --> Mr. Wolfsheim (PERSON)\n",
      "14 --> Oxford (GPE)\n",
      "13 --> Catherine (PERSON)\n",
      "11 --> Jordan Baker (PERSON)\n",
      "10 --> East (LOCATION)\n",
      "10 --> Wolfsheim (PERSON)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence for comparation:\n",
      "East Egg (LOCATION)\n",
      "Tom Buchanans (ORGANIZATION)\n",
      "Daisy (PERSON)\n",
      "Tom (PERSON)\n",
      "Chicago (GPE)\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "ne_chunked = nltk.ne_chunk(tagged)\n",
    "\n",
    "ner = {}\n",
    "for entity in ne_chunked:\n",
    "    if isinstance(entity, nltk.tree.Tree):\n",
    "        t = \" \".join([word for word, tag in entity.leaves()])\n",
    "        ent = entity.label()\n",
    "        if t not in ner:\n",
    "            ner[t] = [ent, 0]\n",
    "        ner[t][1] += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "sort_ner = sorted(ner.items(), key=lambda entity: entity[1][1], reverse=True)\n",
    "print('NER Top 20')\n",
    "print(\"count --> entity\\n\"+\"-\"*80)\n",
    "for s in sort_ner[:20]:\n",
    "    print(\"{} --> {}\".format(s[1][1], s[0]+\" (\"+s[1][0]+\")\"))\n",
    "\n",
    "\n",
    "print(\"\\n\"+\"-\"*80)    \n",
    "print(\"\\nSentence for comparation:\")\n",
    "tokens = nltk.word_tokenize(text_for_comparation)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "ne_chunked_bis = nltk.ne_chunk(tagged)\n",
    "for entity in ne_chunked_bis:\n",
    "    if isinstance(entity, nltk.tree.Tree):\n",
    "        t = \" \".join([word for word, tag in entity.leaves()])\n",
    "        ent = entity.label()\n",
    "        print(t+\" (\"+ent+\")\")\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 ) NER with custom patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 --> Gatsby (NNP)\n",
      "184 --> Tom (NNP)\n",
      "167 --> Daisy (NNP)\n",
      "83 --> Mr. (NNP)\n",
      "75 --> Wilson (NNP)\n",
      "64 --> Jordan (NNP)\n",
      "44 --> New (NNP)\n",
      "39 --> Baker (NNP)\n",
      "34 --> Miss (NNP)\n",
      "31 --> Mrs. (NNP)\n",
      "30 --> West (NNP)\n",
      "30 --> York (NNP)\n",
      "30 --> Wolfsheim (NNP)\n",
      "29 --> Egg (NNP)\n",
      "22 --> Buchanan (NNP)\n",
      "22 --> Myrtle (NNP)\n",
      "21 --> Michaelis (NNP)\n",
      "20 --> Nick (NNP)\n",
      "19 --> God (NNP)\n",
      "18 --> Chicago (NNP)\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "tokens = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "tagged = [nltk.pos_tag(sent) for sent in tokens]\n",
    "tagged_entities = {}\n",
    "entity = []\n",
    "\n",
    "adjectives = ['JJ']\n",
    "nouns = ['NNP', 'NNPS'] # ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "for sentence in tagged:\n",
    "    for word in sentence:\n",
    "        word_txt = word[0]\n",
    "        word_tag = word[1]\n",
    "        if not entity: \n",
    "            if word_tag in adjectives: # match adjectives\n",
    "                entity.append(word)\n",
    "                continue # keep building the entity\n",
    "\n",
    "            elif word_tag in nouns:  # match proper nouns\n",
    "                entity.append(word)\n",
    "                entity_str = \" \".join([word[0] for word in entity])\n",
    "                if entity_str not in tagged_entities:\n",
    "                    tagged_entities[entity_str] = [entity, 0]\n",
    "                tagged_entities[entity_str][1] += 1\n",
    "                # entity complete, look for the next one\n",
    "\n",
    "        else:  # if the entity isn't empty look at the last item \n",
    "            if entity[-1][1] in adjectives: # match adjectives \n",
    "                if word_tag == 'JJ': \n",
    "                    entity.append(word)\n",
    "                    continue # keep building the entity\n",
    "\n",
    "                elif word_tag in nouns:  # match proper nouns\n",
    "                    entity.append(word)\n",
    "                    entity_str = \" \".join([word[0] for word in entity])\n",
    "                    if entity_str not in tagged_entities:\n",
    "                        tagged_entities[entity_str] = [entity, 0]\n",
    "                    tagged_entities[entity_str][1] += 1\n",
    "                    # entity complete, look for the next one\n",
    "\n",
    "        entity = []\n",
    "\n",
    "sorted_custom = sorted(tagged_entities.items(), key=lambda entity: entity[1][1], reverse=True)\n",
    "for e in sorted_custom[:20]:\n",
    "    print(\"{} --> {}\".format(e[1][1], e[0]+\" (\"+e[1][0][0][1]+\")\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 ) Custom entity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wikipedia_text(name):\n",
    "    try:\n",
    "        page = wikipedia.page(name)\n",
    "    except:\n",
    "        return \"a Thing\"\n",
    "    \n",
    "    tagged_tokens = nltk.pos_tag(nltk.word_tokenize(page.summary))\n",
    "    \n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(tagged_tokens)\n",
    "    \n",
    "    for entity in result:\n",
    "        if isinstance(entity, nltk.tree.Tree):\n",
    "            return \" \".join([word for word, tag in entity.leaves()])\n",
    "        else:\n",
    "            continue    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 ) wikipedia classification with step n°3 entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gatsby  -  a Thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideariotto/anaconda3/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/davideariotto/anaconda3/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom  -  a Thing\n",
      "Daisy  -  A day\n",
      "Wilson  -  a Thing\n",
      "Jordan  -  الأردن\n",
      "New York  -  a Thing\n",
      "Miss Baker  -  a squirrel monkey\n",
      "Mr. Gatsby  -  the titular fictional character\n",
      "Michaelis  -  a Thing\n",
      "Nick  -  a Thing\n",
      "West Egg  -  a Thing\n",
      "Chicago  -  shih-KAH-goh\n",
      "Tom Buchanan  -  novel\n",
      "Myrtle  -  a Thing\n",
      "Mr. Wolfsheim  -  novel\n",
      "Oxford  -  a city\n",
      "Catherine  -  derivation\n",
      "Jordan Baker  -  a Thing\n",
      "East  -  the compass\n",
      "Wolfsheim  -  a Thing\n"
     ]
    }
   ],
   "source": [
    "# with the most common words from the whole text\n",
    "for e in sort_ner[:20]:\n",
    "    print(e[0], ' - ', wikipedia_text(e[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across  -  a Thing\n",
      "the  -  a grammatical article\n",
      "courtesy  -  the word\n",
      "bay  -  A day\n",
      "the  -  a grammatical article\n",
      "white  -  a Thing\n",
      "palaces  -  A palace\n",
      "of  -  scale\n",
      "fashionable  -  Fashion\n",
      "East Egg  -  a Thing\n",
      "glittered  -  a Thing\n",
      "along  -  a Thing\n",
      "the  -  a grammatical article\n",
      "water  -  a Thing\n",
      ",  -  The comma\n",
      "and  -  a Thing\n",
      "the  -  a grammatical article\n",
      "history  -  historía\n",
      "of  -  scale\n",
      "the  -  a grammatical article\n",
      "summer  -  Summer\n",
      "really  -  a Thing\n",
      "begins  -  بگعان\n",
      "on  -  a Thing\n",
      "the  -  a grammatical article\n",
      "evening  -  day\n",
      "I  -  a Thing\n",
      "drove  -  a Thing\n",
      "over  -  a Thing\n",
      "there  -  a third-person pronoun\n",
      "to  -  a Thing\n",
      "have  -  a Thing\n",
      "dinner  -  a Thing\n",
      "with  -  a Thing\n",
      "Tom Buchanans  -  a Thing\n",
      ".  -  The full stop\n",
      "Daisy  -  A day\n",
      "was  -  a Thing\n",
      "my  -  m\n",
      "second  -  symbol\n",
      "cousin  -  the lineal\n",
      "once  -  unit\n",
      "removed  -  a Thing\n",
      "and  -  a Thing\n",
      "I  -  a Thing\n",
      "'d  -  uppercase\n",
      "known  -  a form\n",
      "Tom  -  a Thing\n",
      "in  -  a Thing\n",
      "college  -  A college\n",
      ".  -  The full stop\n",
      "And  -  a Thing\n",
      "just  -  a Thing\n",
      "after  -  a Thing\n",
      "the  -  a grammatical article\n",
      "war  -  conflict\n",
      "I  -  a Thing\n",
      "spent  -  a Thing\n",
      "two  -  a number\n",
      "days  -  A day\n",
      "with  -  a Thing\n",
      "them  -  a third-person pronoun\n",
      "in  -  a Thing\n",
      "Chicago  -  shih-KAH-goh\n"
     ]
    }
   ],
   "source": [
    "# just the couple sentences for comparison\n",
    "for e in ne_chunked_bis:\n",
    "    x = \"\"\n",
    "    if(type(e[0]) is tuple):\n",
    "        if len(e)>1:\n",
    "            x = e[0][0] + \" \" + e[1][0]\n",
    "        else:\n",
    "            x = e[0][0]\n",
    "    else:\n",
    "        x = e[0]\n",
    "    print(x, ' - ', wikipedia_text(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 ) wikipedia classification with step n°4 entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gatsby  -  a Thing\n",
      "Tom  -  a Thing\n",
      "Daisy  -  A day\n",
      "Mr.  -  a Thing\n",
      "Wilson  -  a Thing\n",
      "Jordan  -  الأردن\n",
      "New  -  a Thing\n",
      "Baker  -  a Thing\n",
      "Miss  -  an intrinsic property\n",
      "Mrs.  -  contracted form\n",
      "West  -  a Thing\n",
      "York  -  a cathedral city\n",
      "Wolfsheim  -  a Thing\n",
      "Egg  -  An egg\n",
      "Buchanan  -  a Thing\n",
      "Myrtle  -  a Thing\n",
      "Michaelis  -  a Thing\n",
      "Nick  -  a Thing\n",
      "God  -  a chemical element\n",
      "Chicago  -  shih-KAH-goh\n"
     ]
    }
   ],
   "source": [
    "# whole text\n",
    "for e in sorted_custom[:20]:\n",
    "    print(e[0], ' - ', wikipedia_text(e[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 ) Language model classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "count = Counter(filtered_tokens)\n",
    "sort_filtered_tokens = sorted(count.items(), key=lambda count:count[1], reverse=True)\n",
    "ner_input = [t[0] for t in sort_filtered_tokens]\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "ner_results = nlp(ner_input)\n",
    "ner_results = [n for n in ner_results if n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: PERSON\n",
      "['G', 'Tom', 'Daisy', 'Wilson', 'Baker', 'Wolf', 'Buchanan', 'Nick', 'Myrtle', 'Michael', 'God', 'M', 'Catherine', 'Long', 'Cody', 'George', 'Jay', 'Carr', 'Sloane', 'Dan', 'K', 'Meyer', 'J', 'James', 'T', 'Luc', 'Tell', 'Ba', 'Jimmy', 'B', 'Roosevelt', 'Hill', 'R', 'O', 'Walter', 'Buchanan', 'C', 'Barbara', 'Will', 'Ella', 'Kaye', 'M', 'Simon', 'Carlo', 'To', 'Edgar', 'P', 'Cecil', 'Earl', 'Mu', 'Fe', 'Henry', 'A', 'Kat', 'Taylor', 'Con', 'Fe', 'Ewing', 'G', '##G', 'Mid', 'Morgan', 'Mae', 'De', 'York', 'John', 'D', 'Peter', 'Peter', 'Kaiser', 'Wilhelm', 'Dai']\n",
      "Category: ORGANIZATION\n",
      "['Jordan', 'York', 'Oxford', 'G', 'Louisville', 'THE', 'Yale', 'Avenue', 'Park', 'Chester', 'Metro', 'College', 'Rise', 'Star', 'bureau', 'Point', 'Monte', 'Bel', 'Legion', 'Port', 'Detroit', 'T', 'Southampton', 'No', 'Dukes', 'B', 'Dodge', 'News', 'Columbus', 'H', 'Ville', 'Colonial', 'Society', 'D', 'Goddard', 'C', 'Post', 'J', 'Springs', 'Palm', 'Queens', 'GE', 'Ford', 'Rockefeller', 'E', 'SH', 'Marseille', 'Mediterranean', 'Beast', 'Tribune', 'Rolls', 'York', 'Fr']\n",
      "Category: LOCATION\n",
      "['West', 'Chicago', 'Island', 'East', 'B', 'E', 'Montenegro', 'France', 'C', 'Haven', 'Lake', 'earth', 'Broadway', 'England', 'Plaza', 'Finn', 'IN', 'G', 'North', 'Europe', 'Jersey', 'S', 'Arm', 'Santa', 'America', 'Forest', 'Versailles', 'Sea', 'Bridge', 'Pennsylvania', 'swamps', 'ditch', 'City', 'ME', 'Central', 'Village', 'universe', 'St', 'Minnesota', 'ballroom', 'Crossing', 'F', 'Washington', 'Hemisphere', 'Normandy', 'Shore', 'California', 'West', 'Ashe', 'Beach', 'Wake', '##oh', 'heavens', 'W', 'Sol', 'Castile']\n",
      "Category: MISCELLANEOUS\n",
      "['Miss', 'World', 'American', 'French', 'Finnish', 'Italian', 'War', 'Catholic', 'Americans', 'German', 'Were', 'Lutheran', 'Open', 'Negro', 'Te', 'Western', 'Georgian', 'Nordic', 'Nordic']\n",
      "Category: O\n",
      "['Jordan', 'West', 'York', 'Chicago', 'Island', 'East', 'Oxford', 'G', 'B', 'Louisville', 'E', 'Montenegro', 'France', 'C', 'THE', 'Haven', 'Yale', 'Lake', 'earth', 'Avenue', 'Park', 'Broadway', 'Chester', 'England', 'Plaza', 'Finn', 'IN', 'G', 'North', 'Europe', 'Jersey', 'S', 'Metro', 'College', 'Arm', 'Santa', 'America', 'Forest', 'Rise', 'Star', 'Versailles', 'bureau', 'Point', 'Sea', 'Monte', 'Bridge', 'Pennsylvania', 'swamps', 'ditch', 'City', 'Bel', 'Legion', 'Port', 'ME', 'Central', 'Village', 'Detroit', 'T', 'universe', 'St', 'Minnesota', 'ballroom', 'Crossing', 'Southampton', 'F', 'No', 'Dukes', 'B', 'Washington', 'Dodge', 'News', 'Hemisphere', 'Columbus', 'H', 'Ville', 'Normandy', 'Colonial', 'Society', 'Shore', 'D', 'Goddard', 'California', 'C', 'Post', 'West', 'J', 'Ashe', 'Springs', 'Palm', 'Beach', 'Wake', '##oh', 'heavens', 'Queens', 'GE', 'W', 'Sol', 'Ford', 'Rockefeller', 'E', 'SH', 'Marseille', 'Mediterranean', 'Beast', 'Tribune', 'Rolls', 'York', 'Castile', 'Fr']\n"
     ]
    }
   ],
   "source": [
    "# I select just a subset for a clear output (of course it coud be done with every entity)\n",
    "res = ner_results[:200]\n",
    "\n",
    "# Group by the 4 different entities\n",
    "people = [n[0]['word'] for n in res if \"PER\" in n[0]['entity']]\n",
    "organizations = [n[0]['word'] for n in res if \"ORG\" in n[0]['entity']]\n",
    "locations = [n[0]['word'] for n in res if \"LOC\" in n[0]['entity']]\n",
    "misc = [n[0]['word'] for n in res if \"MIS\" in n[0]['entity']]\n",
    "others = [n[0]['word'] for n in res if \"O\" in n[0]['entity']]\n",
    "\n",
    "# Print results\n",
    "print(\"Category: PERSON\")\n",
    "print(people)\n",
    "\n",
    "print(\"Category: ORGANIZATION\")\n",
    "print(organizations)\n",
    "\n",
    "print(\"Category: LOCATION\")\n",
    "print(locations)\n",
    "\n",
    "print(\"Category: MISCELLANEOUS\")\n",
    "print(misc)\n",
    "\n",
    "print(\"Category: O\")\n",
    "print(others)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "I haven't had particular issues during this task except that I was expecting better results, especially from the wikipedia-based classifier.\n",
    "A possible extension could be classifying various books (I mean determing a genre) based on the entites, focusing especially on the \"other\" category (for example if see that the verbs \"fight\",\"die\",\"suffer\" are common, the book could be a tragedy) or using a more advanced ner classifier that can distinguish more than just 4 classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
